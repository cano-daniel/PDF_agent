{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87963518",
   "metadata": {},
   "source": [
    "# Local RAG  tests "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1d0e2dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- ESCENARIO 2: PROCESANDO NUEVO ARCHIVO ---\n",
      "‚úÖ main_notes.pdf agregado e indexado correctamente.\n",
      "üîç An√°lisis del nuevo documento:\n",
      "\n",
      "üìç main_notes.pdf (P√°g. 2):\n",
      "-> Contents\n",
      "I Supervised learning 5\n",
      "1 Linear regression 8\n",
      "1.1 LMS algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . 9\n",
      "1.2 The normal equations . . . . . . . . . . . . . . . . . . . . . . . 13...\n",
      "\n",
      "üìç main_notes.pdf (P√°g. 214):\n",
      "-> Bibliography\n",
      "Mikhail Belkin, Daniel Hsu, Siyuan Ma, and Soumik Mandal. Reconciling\n",
      "modern machine-learning practice and the classical bias‚Äìvariance trade-\n",
      "oÓÄÉ.Proceedings of the National Academy of Sci...\n",
      "\n",
      "üìç main_notes.pdf (P√°g. 216):\n",
      "-> 215\n",
      "Blake Woodworth, Suriya Gunasekar, Jason D Lee, Edward Moroshko, Pe-\n",
      "dro Savarese, Itay Golan, Daniel Soudry, and Nathan Srebro. Kernel and\n",
      "rich regimes in overparametrized models.arXiv preprint a...\n"
     ]
    }
   ],
   "source": [
    "from RAG import LocalRAGAgent\n",
    "\n",
    "print(\"\\n--- ESCENARIO 2: PROCESANDO NUEVO ARCHIVO ---\")\n",
    "\n",
    "# Aqu√≠ le pasamos la ruta de un archivo que NO est√° en nuestra carpeta local todav√≠a\n",
    "ruta_nuevo_pdf = \"main_notes.pdf\"\n",
    "\n",
    "# El agente lo copiar√° a local_rag/pdf_files e iniciar√° el Ryzen 7 para procesarlo\n",
    "rag_nuevo = LocalRAGAgent(pdf_path=ruta_nuevo_pdf)\n",
    "\n",
    "query_2 = \"Subjects handled in this new book?\"\n",
    "resultados_2 = rag_nuevo.search(query_2, k=3)\n",
    "\n",
    "print(f\"üîç An√°lisis del nuevo documento:\")\n",
    "for res in resultados_2:\n",
    "    print(f\"\\nüìç {res['archivo']} (P√°g. {res['pagina']}):\")\n",
    "    print(f\"-> {res['texto'][:200]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09cf1a4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/projects/PDF_agent/agent/venv_agent/lib64/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö° Cargando base de datos existente con 1 archivos...\n",
      "\n",
      "[main_notes.pdf - P√°g 61]: Chapter 6\n",
      "Support vector machines\n",
      "This set of notes presents the Support Vector Machine (SVM) learning al-\n",
      "gorithm. SVMs are among the best (and many believe are indeed the best)\n",
      "ÓÄæoÓÄÉ-the-shelfÓÄäsupervi...\n",
      "\n",
      "[main_notes.pdf - P√°g 59]: nels. For instance, consider the digit recognition problem, in which given\n",
      "an image (16x16 pixels) of a handwritten digit (0-9), we have toÓÄÑgure out\n",
      "which digit it was. Using either a simple polynomia...\n",
      "--- ESCENARIO 1: CARGANDO LIBRER√çA EXISTENTE ---\n",
      "‚ö° Cargando base de datos existente con 1 archivos...\n",
      "üîç Resultados encontrados para: 'las resdes neuronales como manejan la los problermas no lienales?'\n",
      "\n",
      "[Archivo: main_notes.pdf | P√°gina: 82]\n",
      "Texto: Chapter 7\n",
      "Deep learning\n",
      "We now begin our study of deep learning. In this set of notes, we give an\n",
      "overview of neural networks, discuss vectorization and discuss training neural\n",
      "networks with backpropagation.\n",
      "7.1 Supervised learning with non-linear mo...\n",
      "\n",
      "[Archivo: main_notes.pdf | P√°gina: 84]\n",
      "Texto: 7.2 Neural networks\n",
      "Neural networks refer to broad type of non-linear models/parametrizations\n",
      "hŒ∏(x) that involve combinations of matrix multiplications and other entry-\n",
      "wise non-linear operations. We will start small and slowly build up a neural\n",
      "netw...\n"
     ]
    }
   ],
   "source": [
    "from RAG import LocalRAGAgent\n",
    "# Suponiendo que ya tienes la clase LocalRAGAgent definida arriba\n",
    "print(\"--- ESCENARIO 1: CARGANDO LIBRER√çA EXISTENTE ---\")\n",
    "\n",
    "# Al no pasarle un path, el agente busca en 'local_rag/pdf_files' autom√°ticamente\n",
    "rag_existente = LocalRAGAgent() \n",
    "\n",
    "query_1 = \"las resdes neuronales como manejan la los problermas no lienales?\"\n",
    "resultados = rag_existente.search(query_1, k=2)\n",
    "\n",
    "if resultados:\n",
    "    print(f\"üîç Resultados encontrados para: '{query_1}'\")\n",
    "    for res in resultados:\n",
    "        print(f\"\\n[Archivo: {res['archivo']} | P√°gina: {res['pagina']}]\")\n",
    "        print(f\"Texto: {res['texto'][:250]}...\")\n",
    "else:\n",
    "    print(\"No se encontraron documentos en la carpeta local_rag.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b5bc85",
   "metadata": {},
   "source": [
    "# Agent class test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3564262d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/projects/PDF_agent/agent/venv_agent/lib64/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö° Cargando base de datos existente...\n"
     ]
    }
   ],
   "source": [
    "from agent import dummy_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dad17607",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 10.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The document discusses linear regression in Chapter 1, starting on page 8. It covers the LMS algorithm and the normal equations. It also mentions locally weighted linear regression in section 1.4.\n"
     ]
    }
   ],
   "source": [
    "dummy_friend = dummy_agent()\n",
    "response = dummy_friend.run_chat(\"talk to me about linear regression, and were on the pdf i can find the information?\")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "135fc4b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The provided text includes information about linear regression from several pages:\n",
      "\n",
      "**Page 2 (Table of Contents):**\n",
      "*   Chapter 1 is dedicated to \"Linear Regression\" and starts on page 8.\n",
      "*   It covers:\n",
      "    *   \"LMS algorithm\" (Least Mean Squares) on page 9.\n",
      "    *   \"The normal equations\" on page 13.\n",
      "    *   \"Probabilistic interpretation\" on page 15.\n",
      "    *   \"Locally weighted linear regression\" (optional reading) on page 17.\n",
      "\n",
      "**Pages 7-19:**\n",
      "These pages provide a detailed explanation of linear regression.\n",
      "*   **Chapter 1: Linear Regression:** Introduces supervised learning with examples like predicting housing prices based on living area and number of bedrooms.\n",
      "*   **Hypothesis Representation:** It explains how to represent the hypothesis (prediction function) as a linear function of the input features: hŒ∏(x) = Œ∏‚ÇÄ + Œ∏‚ÇÅx‚ÇÅ + Œ∏‚ÇÇx‚ÇÇ + ... = Œ∏·µÄx.\n",
      "*   **Cost Function:** The cost function J(Œ∏) = 1/2 * Œ£(hŒ∏(x‚ÅΩ‚Å±‚Åæ) - y‚ÅΩ‚Å±‚Åæ)¬≤ is introduced, which is the sum of squared errors.\n",
      "*   **LMS Algorithm (Gradient Descent):** The text describes the gradient descent algorithm to minimize the cost function. It explains both batch gradient descent (updating parameters after processing all training examples) and stochastic gradient descent (updating parameters after each training example).\n",
      "*   **The Normal Equations:** This section provides a closed-form solution for finding the optimal parameters Œ∏ by setting the derivative of the cost function to zero. The solution is Œ∏ = (X·µÄX)‚Åª¬πX·µÄy.\n",
      "*   **Probabilistic Interpretation:** It explains how linear regression with the least-squares cost function can be derived from a probabilistic perspective, assuming the target variables follow a Gaussian distribution. Maximizing the likelihood of the data leads to minimizing the squared error.\n",
      "*   **Locally Weighted Linear Regression (Optional Reading):** This section introduces a non-parametric approach where the algorithm gives more weight to training examples that are closer to the query point. This is in contrast to traditional linear regression, which is a parametric algorithm.\n",
      "\n",
      "**Page 20:**\n",
      "*   This page starts Chapter 2, which is about Classification and Logistic Regression. While it mentions that linear regression can be a starting point for classification, it quickly moves on to introduce logistic regression as a more suitable model for classification tasks.\n",
      "\n",
      "In summary, the core concepts of linear regression, including its algorithms (LMS/gradient descent, normal equations), cost function, and probabilistic interpretation, are thoroughly covered in Chapter 1, pages 8-19. Page 20 begins the discussion on classification, which uses logistic regression.\n"
     ]
    }
   ],
   "source": [
    "response = dummy_friend.run_chat(\"could you go to the pages you mentiuoned and tell me about them making a sumary or what do they talk about ALSO SEARCH IN  THE SURRONDING PAGES YOU THINK IT WOULD BE IMPORTANT\")\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
